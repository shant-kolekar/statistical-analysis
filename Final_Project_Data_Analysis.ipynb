{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd64349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb841d",
   "metadata": {},
   "source": [
    "### Part-I\n",
    "##### What to expect:\n",
    "   * In part-I, we will *__clean the data__*, and will write down each step in detail.\n",
    "        * Read CSV file\n",
    "        * Remove columns which are not requierd in analysis. \n",
    "            * ['address', 'phone']\n",
    "        * Rename columns to some intuitive names\n",
    "        * Handle the null values [drop it]\n",
    "            * The risk of bias arises if the imputed values are not representative of the true missing values, so we will remove missing values as we have enough dataset to work on.\n",
    "        * Drop duplicates\n",
    "        * Remove the irrelevant text from each column, if any\n",
    "            * For example in rating column extract 4.1 from '4.1/5' and convert it to float type.\n",
    "            * In 'online_order' column we want \"Yes or No\", so will remove records which have \n",
    "            values other than \"Yes or No\".\n",
    "            * Convert ['votes', 'approx_cost'] columns to integer.\n",
    "        * Check uniqueness of the data in each column \n",
    "             * If any nan value is created during conversion from string to float or int, handle those records with nan values.\n",
    "        * Remove Non-printable characters from Name column\n",
    "\n",
    "\n",
    "\n",
    "*__Note: First handle missing values and extract substring after that convert to numeric type as missing values and nan values might generate exception.__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b106401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_csv():\n",
    "    path = input('Enter the path to csv file:\\t')\n",
    "    restaurants=pd.read_csv(path)\n",
    "    return restaurants\n",
    "\n",
    "\n",
    "def remove_unwanted_columns():\n",
    "    #call read_data_from_csv() function to get dataframe\n",
    "    \n",
    "    restaurants = read_data_from_csv()\n",
    "    restaurants = restaurants.drop(columns=['address', 'phone'])\n",
    "    \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "def rename_columns():\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    restaurants = remove_unwanted_columns()\n",
    "    \n",
    "    #rename columns,  only these columns will be used in the dataset\n",
    "    restaurants.rename(columns={'rate':'rating',\n",
    "                       'approx_cost(for two people)':'approx_cost',\n",
    "                       'listed_in(type)': 'type'}, inplace=True)\n",
    "   \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "#handle  null values of each column\n",
    "def null_value_check():\n",
    "    \n",
    "    #call rename_columns() function to get dataframe\n",
    "    restaurants=rename_columns()\n",
    "    \n",
    "    #remove all null values from all columns\n",
    "    restaurants.dropna(inplace=True)\n",
    "    \n",
    "    for col in restaurants.columns:\n",
    "        \n",
    "        cnt = restaurants[col].loc[restaurants[col].isnull() == True].count()\n",
    "\n",
    "        if cnt != 0:\n",
    "            print(f'Oops :(, Null values in {col} column')\n",
    "            print(col, cnt)\n",
    "        \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "#find duplicates in the dataset\n",
    "def remove_duplicates():\n",
    "    \n",
    "    #call null_value_check() function to get dataframe\n",
    "    restaurants=null_value_check()\n",
    "    \n",
    "    #droping the duplicates value keeping the first\n",
    "    restaurants.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "#removing irrelevant text from all the columns\n",
    "def removing_irrelevant_text():\n",
    "    \n",
    "    #call remove_duplicates() function to get dataframe\n",
    "    restaurants= remove_duplicates()\n",
    "    \n",
    "    \n",
    "    #Extract ratings 4.1 from 4.1/5\n",
    "    restaurants['rating'] = restaurants['rating'].str.extract(r'^(\\d\\.\\d)')\n",
    "    restaurants['rating'] = restaurants['rating'].astype(float)\n",
    "    \n",
    "    #Remove rows which contains value other than Yes or No\n",
    "    restaurants = restaurants.loc[restaurants['online_order'].isin(['Yes', 'No'])]\n",
    "    \n",
    "    #Convert to float \n",
    "    restaurants['votes'] = restaurants['votes'].astype(int)\n",
    "    restaurants['approx_cost'] = restaurants['approx_cost'].str.replace(',', '').astype(int)\n",
    "    \n",
    "    \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "#check for unique values in each column and handle the irrelevant values\n",
    "def check_for_unique_values():\n",
    "    '''\n",
    "    Handling or removing np.nan values which might arise during the extraction of ratings or \n",
    "    during conversion to float type.\n",
    "    '''\n",
    "    \n",
    "    #call removing_irrelevant_text() function to get dataframe\n",
    "    restaurants = removing_irrelevant_text()\n",
    "    \n",
    "    # Creating copy of the datafram as mutating the same dataframe might cause problems.\n",
    "    restaurants_cp = restaurants.copy()\n",
    "   \n",
    "\n",
    "    for col in restaurants_cp.columns:\n",
    "        if restaurants_cp[col].dtype != 'object':          \n",
    "            for val in restaurants_cp[col].unique():\n",
    "                if math.isnan(val) or np.isnan(val) or pd.isna(val):\n",
    "                    #remove all those rows where val is np.nan \n",
    "                    restaurants = restaurants.loc[np.isnan(restaurants[col]) == False]\n",
    "                    \n",
    "    return restaurants\n",
    "\n",
    "\n",
    "#remove the unknown character from the dataset and export it to \"zomatocleaned.csv\"\n",
    "def remove_the_unknown_character():\n",
    "    '''\n",
    "    remove unknown character from dataset\n",
    "    '''\n",
    "    \n",
    "    #call check_for_unique_values() function to get dataframe\n",
    "    dataframe=check_for_unique_values()\n",
    "    \n",
    "    # define a regular expression pattern to remove unknown characters \n",
    "    # AsCII code for printable chars\n",
    "    pattern = r'[^\\x00-\\x7F]+'\n",
    "\n",
    "    # remove unknown characters from non-numeric columns\n",
    "    for col in dataframe.columns:  \n",
    "        if dataframe[col].dtype == 'object':\n",
    "            dataframe[col] = dataframe[col].apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "    \n",
    "    \n",
    "    #export cleaned Dataset to newcsv file named \"zomatocleaned.csv\"\n",
    "#     dataframe.to_csv('zomato_cleaned.csv')\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cleaned_data():\n",
    "    '''\n",
    "    Returns dataframe where all null values are handled, and \n",
    "    converts all columns to appropriate format.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    path : Path to origianl csv file ('zomato.csv')\n",
    "    \n",
    "    '''\n",
    "    return remove_the_unknown_character()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49329a80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to csv file:\tzomato.csv\n"
     ]
    }
   ],
   "source": [
    "df = cleaned_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee1339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1</td>\n",
       "      <td>775</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>Buffet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name online_order book_table  rating  votes      location      rest_type  \\\n",
       "0  Jalsa          Yes        Yes     4.1    775  Banashankari  Casual Dining   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "\n",
       "                         cuisines  approx_cost    type  \n",
       "0  North Indian, Mughlai, Chinese          800  Buffet  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b382e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
